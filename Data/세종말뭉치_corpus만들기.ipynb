{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, create_engine, ForeignKey\n",
    "from sqlalchemy.ext.declarative import declarative_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///corpus.db', echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SejongCorpus(base):\n",
    "    __tablename__ = 'SEJONG_CORPUS'\n",
    "    \n",
    "    pk = Column('pk', Integer, primary_key=True, autoincrement=True)\n",
    "    ko_text = Column('ko_text', String, nullable=True)\n",
    "    thai_text = Column('thai_text', String, nullable=True)\n",
    "    file_name = Column('file_name', String, nullable=True)\n",
    "    sent_count = Column('sent_count', Integer, nullable=True)\n",
    "    cumsum_count = Column('cumsum_count', Integer, nullable=True)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'pk:{}, ko_text:{}, thai_text:{}'.format(self.pk, self.ko_text, self.thai_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-18 23:03:00,963 INFO sqlalchemy.engine.base.Engine SELECT \"SEJONG_CORPUS\".ko_text AS \"SEJONG_CORPUS_ko_text\", \"SEJONG_CORPUS\".thai_text AS \"SEJONG_CORPUS_thai_text\" \n",
      "FROM \"SEJONG_CORPUS\"\n",
      "2020-08-18 23:03:00,965 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    }
   ],
   "source": [
    "unicode = [r[0] for r in session.query(SejongCorpus.ko_text, SejongCorpus.thai_text).all() if re.match(\".*[\\u2e80-\\u2eff\\u31c0-\\u31ef\\u3200-\\u32ff\\u3400-\\u4dbf\\u4e00-\\u9fbf\\uf900-\\ufaff].*\", r[0]) is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-24 19:02:10,617 INFO sqlalchemy.engine.base.Engine SELECT \"SEJONG_CORPUS\".ko_text AS \"SEJONG_CORPUS_ko_text\", \"SEJONG_CORPUS\".thai_text AS \"SEJONG_CORPUS_thai_text\" \n",
      "FROM \"SEJONG_CORPUS\"\n",
      "2020-08-24 19:02:10,630 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-08-24 19:02:14,599 INFO sqlalchemy.engine.base.Engine SELECT \"SEJONG_CORPUS\".ko_text AS \"SEJONG_CORPUS_ko_text\", \"SEJONG_CORPUS\".thai_text AS \"SEJONG_CORPUS_thai_text\" \n",
      "FROM \"SEJONG_CORPUS\"\n",
      "2020-08-24 19:02:14,599 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    }
   ],
   "source": [
    "ko_corpus = [r[0] for r in session.query(SejongCorpus.ko_text, SejongCorpus.thai_text).all() if re.match(\".*[\\u2e80-\\u2eff\\u31c0-\\u31ef\\u3200-\\u32ff\\u3400-\\u4dbf\\u4e00-\\u9fbf\\uf900-\\ufaff].*\", r[0]) is None and '.' in r[0]]\n",
    "thai_corpus = [r[1]+' ' for r in session.query(SejongCorpus.ko_text, SejongCorpus.thai_text).all() if re.match(\".*[\\u2e80-\\u2eff\\u31c0-\\u31ef\\u3200-\\u32ff\\u3400-\\u4dbf\\u4e00-\\u9fbf\\uf900-\\ufaff].*\", r[0]) is None and '.' in r[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438771, 438771)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ko_corpus), len(thai_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train_ko, corpus_test_ko = train_test_split(ko_corpus, test_size=0.2) # train / test \n",
    "corpus_train_ko, corpus_valid_ko = train_test_split(corpus_train_ko, test_size=0.1) # train / validation\n",
    "corpus_train_th, corpus_test_th = train_test_split(thai_corpus, test_size=0.2) # train /test \n",
    "corpus_train_th, corpus_valid_th = train_test_split(corpus_train_th, test_size=0.1) # train / validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315914, 35102, 87755)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_train_ko), len(corpus_valid_ko), len(corpus_test_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.train.ko', 'w+', encoding='utf-8') as f:\n",
    "    for ko in ko_corpus:\n",
    "        f.write(ko+'|')\n",
    "        \n",
    "with open('corpus.train.th', 'w+', encoding='utf-8') as f:\n",
    "    for th in thai_corpus:\n",
    "        f.write(th+'|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.train.ko', 'w+', encoding='utf-8') as f:\n",
    "    for ko in corpus_train_ko:\n",
    "        f.write(ko+'|')\n",
    "        \n",
    "with open('corpus.valid.ko', 'w+', encoding='utf-8') as f:\n",
    "    for ko in corpus_valid_ko:\n",
    "        f.write(ko+'|')\n",
    "        \n",
    "with open('corpus.test.ko', 'w+', encoding='utf-8') as f:\n",
    "    for ko in corpus_test_ko:\n",
    "        f.write(ko+'|')\n",
    "        \n",
    "with open('corpus.train.th', 'w+', encoding='utf-8') as f:\n",
    "    for th in corpus_train_th:\n",
    "        f.write(th+'|')\n",
    "        \n",
    "with open('corpus.valid.th', 'w+', encoding='utf-8') as f:\n",
    "    for th in corpus_valid_th:\n",
    "        f.write(th+'|')\n",
    "        \n",
    "with open('corpus.test.th', 'w+', encoding='utf-8') as f:\n",
    "    for th in corpus_test_th:\n",
    "        f.write(th+'|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
