{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_ko_th.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVvC0bmpuiEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugsrVLg2xrC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML-_UD7KxrIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/bert-nmt/bert-nmt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcsyQG_XxrK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd bert-nmt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqKynflCx0jW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --editable ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TojZLF5dxMsC",
        "colab_type": "text"
      },
      "source": [
        "## 1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U5wGkQx7t6",
        "colab_type": "text"
      },
      "source": [
        "### 1-1. get tokenized&bped files \n",
        "=> train.ko train.th valid.ko valid.th test.ko test.th\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGSpLoU00Sp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/bert-nmt/examples/translation/ko-th_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJqXxxYr0StS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file upload\n",
        "# test.tags.ko-th.th  train.tags.ko-th.th\n",
        "# test.tags.ko-th.ko  train.tags.ko-th.ko"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5chCin7Xd6Wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/bert-nmt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rJNXKpTQ00J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! rm examples/translation/prepare-koth.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5LKS0fA0X9V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0cc6116f-726f-446c-c982-f4f16b46e26d"
      },
      "source": [
        "%%writefile examples/translation/prepare-koth.sh\n",
        "\n",
        "echo 'Cloning Moses github repository (for tokenization scripts)...'\n",
        "git clone https://github.com/moses-smt/mosesdecoder.git\n",
        "\n",
        "echo 'Cloning Subword NMT repository (for BPE pre-processing)...'\n",
        "git clone https://github.com/rsennrich/subword-nmt.git\n",
        "\n",
        "SCRIPTS=mosesdecoder/scripts\n",
        "TOKENIZER=$SCRIPTS/tokenizer/tokenizer.perl\n",
        "LC=$SCRIPTS/tokenizer/lowercase.perl\n",
        "CLEAN=$SCRIPTS/training/clean-corpus-n.perl\n",
        "BPEROOT=subword-nmt\n",
        "BPE_TOKENS=10000\n",
        "\n",
        "\n",
        "if [ ! -d \"$SCRIPTS\" ]; then\n",
        "    echo \"Please set SCRIPTS variable correctly to point to Moses scripts.\"\n",
        "    exit\n",
        "fi\n",
        "\n",
        "src=ko\n",
        "tgt=th\n",
        "lang=ko-th\n",
        "prep=iwslt14.tokenized.ko-th\n",
        "tmp=$prep/tmp\n",
        "orig=ko-th_data\n",
        "\n",
        "\n",
        "mkdir -p $tmp $prep\n",
        "echo $orig $tmp $prep\n",
        "\n",
        "\n",
        "echo \"pre-processing train data...\"\n",
        "for l in $src $tgt; do\n",
        "    f=train.tags.$lang.$l\n",
        "    tok=train.tags.$lang.tok.$l\n",
        "\n",
        "    cat $orig/$f | \\\n",
        "    perl $TOKENIZER -threads 8 -l $l > $tmp/$tok\n",
        "    echo \"\"\n",
        "done\n",
        "perl $CLEAN -ratio 1.5 $tmp/train.tags.$lang.tok $src $tgt $tmp/train.tags.$lang.clean 1 175\n",
        "for l in $src $tgt; do\n",
        "    perl $LC < $tmp/train.tags.$lang.clean.$l > $tmp/train.tags.$lang.$l\n",
        "done\n",
        "\n",
        "\n",
        "\n",
        "echo \"pre-processing test data...\"\n",
        "for l in $src $tgt; do\n",
        "    f=test.tags.$lang.$l\n",
        "    tok=test.tags.$lang.tok.$l\n",
        "\n",
        "    cat $orig/$f | \\\n",
        "    perl $TOKENIZER -threads 8 -l $l > $tmp/$tok\n",
        "    echo \"\"\n",
        "done\n",
        "\n",
        "\n",
        "echo \"creating train, valid, test...\"\n",
        "for l in $src $tgt; do\n",
        "    awk '{if (NR%23 == 0)  print $0; }' $tmp/train.tags.$lang.$l > $tmp/valid.$l\n",
        "    awk '{if (NR%23 != 0)  print $0; }' $tmp/train.tags.$lang.$l > $tmp/train.$l\n",
        "\n",
        "    cat $orig/test.tags.$lang.$l  > $tmp/test.$l #파일 여러개를 합쳐서 하나의 큰 파일을 만듦\n",
        "done\n",
        "\n",
        "\n",
        "TRAIN=$tmp/train.ko-th\n",
        "BPE_CODE=$prep/code\n",
        "rm -f $TRAIN\n",
        "for l in $src $tgt; do\n",
        "    cat $tmp/train.$l >> $TRAIN  #기존에 있는 train.en-de에 train.$l 의 내용을 덧붙여준다.\n",
        "done\n",
        "\n",
        "echo \"learn_bpe.py on ${TRAIN}...\"\n",
        "python $BPEROOT/learn_bpe.py -s $BPE_TOKENS < $TRAIN > $BPE_CODE\n",
        "\n",
        "for L in $src $tgt; do\n",
        "    for f in train.$L valid.$L test.$L; do\n",
        "        echo \"apply_bpe.py to ${f}...\"\n",
        "        python $BPEROOT/apply_bpe.py -c $BPE_CODE < $tmp/$f > $prep/$f\n",
        "    done\n",
        "done"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing examples/translation/prepare-koth.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be-otQLL0YNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd examples/translation/ && sh ./prepare-koth.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvIhmW34yFKF",
        "colab_type": "text"
      },
      "source": [
        "### 1-2. get input file for BERT model\n",
        "=> train.ko train.th valid.ko valid.th test.ko test.th train.bert.ko valid.bert.ko test.bert.ko\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaB9nLgh2i3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cp: 파일을 이름을 바꾸어 복사\n",
        "!cp examples/translation/makedataforbert.sh examples/translation/iwslt14.tokenized.ko-th/makedataforbert.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaagJGbQ25vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd examples/translation/iwslt14.tokenized.ko-th && sh ./makedataforbert.sh ko"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuNZyFL9yO8v",
        "colab_type": "text"
      },
      "source": [
        "### 1-3. preprocess data like Fairseq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2qD1R6c4Kf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT='examples/translation/iwslt14.tokenized.ko-th'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvsE1QB4x7IH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python preprocess.py --source-lang ko --target-lang th \\\n",
        "  --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n",
        "  --destdir /content/bert-nmt/examples/translation/preprocess.ko-th  --joined-dictionary --bert-model-name bert-base-cased"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTTH-ii6xMw4",
        "colab_type": "text"
      },
      "source": [
        "## 2. Train a vanilla NMT model using Fairseq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHqasbuk4k_N",
        "colab_type": "text"
      },
      "source": [
        "### 2-1. train a Transformer translation model over this data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JOYYxJeoQM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvtGPD22p6Fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iERl6uIqAeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd fairseq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3veWQgWqAlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --editable ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bf9wc5zEqe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sacremoses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wDjJtFA3wHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train.py \\\n",
        "    /content/bert-nmt/examples/translation/preprocess.ko-th \\\n",
        "    --arch transformer_iwslt_de_en --share-decoder-input-output-embed \\\n",
        "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
        "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
        "    --dropout 0.3 --weight-decay 0.0001 \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "    --max-tokens 4096 \\\n",
        "    --save-dir /content/drive/My\\ Drive/bert_on_collab/checkpoints_pretrain \\\n",
        "    --eval-bleu \\\n",
        "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
        "    --eval-bleu-detok moses \\\n",
        "    --eval-bleu-remove-bpe \\\n",
        "    --eval-bleu-print-samples \\\n",
        "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
        "    | tee -a /content/drive/My\\ Drive/bert_on_collab/checkpoints_pretrain/training.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzoWriZ7xM2k",
        "colab_type": "text"
      },
      "source": [
        "## 3. Train a BERT-fused NMT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmjCYTX14zAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm training_script.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntWerMgUyhY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile training_script.sh\n",
        "#!/usr/bin/env bash\n",
        "nvidia-smi\n",
        "\n",
        "cd .\n",
        "python3 -c \"import torch; print(torch.__version__)\"\n",
        "\n",
        "src=ko\n",
        "tgt=th\n",
        "bedropout=0.5\n",
        "ARCH=transformer_iwslt_de_en\n",
        "DATAPATH=/content/bert-nmt/examples/translation/preprocess.ko-th\n",
        "#SAVEDIR=/content/drive/My\\ Drive/bert_on_collab/checkpoints_minitrain\n",
        "mkdir /content/drive/My\\ Drive/bert_on_collab/checkpoints_train\n",
        "if [ ! -f /content/drive/My\\ Drive/bert_on_collab/checkpoints_train/checkpoint_nmt.pt ]\n",
        "then\n",
        "    cp /content/drive/My\\ Drive/bert_on_collab/checkpoints_pretrain/checkpoint_best.pt /content/drive/My\\ Drive/bert_on_collab/checkpoints_train/checkpoint_nmt.pt\n",
        "fi\n",
        "if [ ! -f \"/content/drive/My\\ Drive/bert_on_collab/checkpoints_train/checkpoint_last.pt\" ]\n",
        "then\n",
        "warmup=\"--warmup-from-nmt --reset-lr-scheduler\"\n",
        "else\n",
        "warmup=\"\"\n",
        "fi\n",
        "\n",
        "python train.py $DATAPATH \\\n",
        "-a $ARCH --optimizer adam --lr 0.0005 -s $src -t $tgt --label-smoothing 0.1 \\\n",
        "--dropout 0.3 --max-tokens 4000 --min-lr '1e-09' --lr-scheduler inverse_sqrt --weight-decay 0.0001 \\\n",
        "--criterion label_smoothed_cross_entropy --max-update 150000 --warmup-updates 4000 --warmup-init-lr '1e-07' \\\n",
        "--adam-betas '(0.9,0.98)' \\\n",
        "--max-epoch 4 \\\n",
        "--save-dir /content/drive/My\\ Drive/bert_on_collab/checkpoints_train --share-all-embeddings $warmup \\\n",
        "--encoder-bert-dropout --encoder-bert-dropout-ratio $bedropout \\\n",
        "--bert-model-name bert-base-multilingual-cased \\\n",
        " | tee -a /content/drive/My\\ Drive/bert_on_collab/checkpoints_train/training.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9kZyKJS5O1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sh ./training_script.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3CREo6cxM7d",
        "colab_type": "text"
      },
      "source": [
        "## 4. Generate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpQGpYdHyl_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python generate.py  --quiet --bert-model-name bert-base-multilingual-cased \\\n",
        "                    --path /content/drive/My\\ Drive/bert_on_collab/checkpoints_train/checkpoint_best.pt \\\n",
        "                    examples/translation/iwslt14.tokenized.ko-th \\\n",
        "                    | tee -a /content/drive/My\\ Drive/bert_on_collab/checkpoints_train/generate.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjPNDLTaxNAW",
        "colab_type": "text"
      },
      "source": [
        "## 5. Interactive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxB-6IqdIhp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_lst = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650GXbLWIhtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_file_path='/content/bert-nmt/test_input.ko'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sjfd35hIlBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(output_file_path,\"w+\", encoding='utf-8') as f:\n",
        "  for s in input_lst:\n",
        "    f.write(s+'\\n')\n",
        "  f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8klz7RcDxmHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile interactive_script.sh\n",
        "\n",
        "MOSE=/content/bert-nmt/examples/translation/mosesdecoder\n",
        "bpefile=test_input.ko\n",
        "src=ko\n",
        "tgt=th\n",
        "DATAPATH=/content/bert-nmt/examples/translation/preprocess.ko-th\n",
        "\n",
        "sed -r 's/(@@ )|(@@ ?$)//g' $bpefile > $bpefile.debpe\n",
        "$MOSE/scripts/tokenizer/detokenizer.perl -l $src < $bpefile.debpe > $bpefile.debpe.detok\n",
        "paste -d \"\\n\" $bpefile $bpefile.debpe.detok > $bpefile.in\n",
        "cat $bpefile.in | python interactive.py \\\n",
        "$DATAPATH \\\n",
        "-s $src -t $tgt \\\n",
        "--path /content/drive/My\\ Drive/bert_on_collab/checkpoints_train/checkpoint_best.pt \\\n",
        "--buffer-size 1024 --batch-size 128 --beam 5 --remove-bpe  \n",
        "> output.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSzOJ1xTxqfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sh ./interactive_script.sh"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}